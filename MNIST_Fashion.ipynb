{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages in the current kernel\n",
        "import sys\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"Python executable: {sys.executable}\")\n",
        "\n",
        "# Install packages if not available\n",
        "try:\n",
        "    import torch\n",
        "    print(f\"✓ torch {torch.__version__} is already installed\")\n",
        "except ImportError:\n",
        "    print(\"Installing torch...\")\n",
        "    %pip install torch torchvision --quiet\n",
        "    import torch\n",
        "    print(f\"✓ torch {torch.__version__} installed successfully\")\n",
        "\n",
        "try:\n",
        "    import torchvision\n",
        "    print(f\"✓ torchvision {torchvision.__version__} is already installed\")\n",
        "except ImportError:\n",
        "    print(\"Installing torchvision...\")\n",
        "    %pip install torchvision --quiet\n",
        "    import torchvision\n",
        "    print(f\"✓ torchvision {torchvision.__version__} installed successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUyZdPp_B5IF",
        "outputId": "1ece5b91-8569-4a03-f2e1-8d731b45d9ae"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m                                                           \u001b[38;5;66;03m#----------------------------------------\u001b[39;00m\n\u001b[32m      2\u001b[39m                                                                    \u001b[38;5;66;03m#Student Information#\u001b[39;00m\n\u001b[32m      3\u001b[39m                                                           \u001b[38;5;66;03m#----------------------------------------\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m#Import Pytorch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m                      \u001b[38;5;66;03m# Deep learning framework\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m#Import torch neural network\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m             \u001b[38;5;66;03m# Neural network layers, activations, etc.\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "                                                          #----------------------------------------\n",
        "                                                                   #Student Information#\n",
        "                                                          #----------------------------------------\n",
        "                                                           # David Engstrom - Student ID: 301537614\n",
        "                                                           # Brian Salas    - Student ID: 301789398\n",
        "\n",
        "# This dataset is for our second (student choice) neural network - using MNIST Fashion\n",
        "\n",
        "#Import Pytorch\n",
        "import torch                      # Deep learning framework\n",
        "#Import torch neural network\n",
        "import torch.nn as nn             # Neural network layers, activations, etc.\n",
        "#Import torch optimization\n",
        "import torch.optim as optim       # Optimization algorithms (Adam, SGD, etc.)\n",
        "#Get the torch DataLoader class\n",
        "from torch.utils.data import DataLoader  # For batching and shuffling data\n",
        "#Get the ready-to-use datasets and image preprocessing functions\n",
        "from torchvision import datasets, transforms # Provides datasets like FashionMNIST\n",
        "#Handles file paths cleaner and safer across OS\n",
        "from pathlib import Path\n",
        "\n",
        "#----------------------------\n",
        "# Config / Hyperparameters\n",
        "#----------------------------\n",
        "BATCH_SIZE = 128   # Number of samples per mini-batch\n",
        "EPOCHS = 5         # Number of times the dataset is processed fully\n",
        "LR = 1e-3          # Learning rate for optimizer\n",
        "SEED = 11          # Random seed for reproducibility\n",
        "DEVICE = \"cpu\"     # Run on CPU only\n",
        "\n",
        "torch.manual_seed(SEED)  # Fix randomness for reproducibility\n",
        "\n",
        "#----------------------------\n",
        "# Fashion-MNIST preprocessing\n",
        "#----------------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),               # Convert images to tensors\n",
        "    transforms.Normalize((0.5,), (0.5,)) # Normalize pixel values to mean=0.5, std=0.5\n",
        "])\n",
        "\n",
        "#Load the Fashion-MNIST training dataset (60,000 images)\n",
        "train_ds = datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=transform)\n",
        "\n",
        "#Load the Fashion-MNIST test dataset (10,000 images)\n",
        "test_ds  = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=transform)\n",
        "\n",
        "#Wrap training dataset in DataLoader: batches of BATCH_SIZE, shuffled each epoch\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "#Wrap test dataset in DataLoader: batches of BATCH_SIZE, no shuffle\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "#----------------------------\n",
        "# Define a Convolutional Neural Network (CNN) for Fashion-MNIST\n",
        "#----------------------------\n",
        "class FashionCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Convolutional feature extractor\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),   # input=1 channel (grayscale), output=32 filters\n",
        "            nn.ReLU(inplace=True),                        # activation function\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # 32 → 64 filters\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),                              # downsample: 28x28 → 14x14\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # 64 → 128 filters\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),                              # downsample: 14x14 → 7x7\n",
        "        )\n",
        "\n",
        "        # Fully connected classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),                                 # flatten into 1D vector\n",
        "            nn.Linear(128 * 7 * 7, 256),                  # fully connected layer\n",
        "            nn.ReLU(inplace=True),                        # activation\n",
        "            nn.Dropout(0.3),                              # dropout to reduce overfitting\n",
        "            nn.Linear(256, 10)                            # output layer: 10 classes (clothing categories)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)      # apply convolution + pooling\n",
        "        x = self.classifier(x)    # apply fully connected layers\n",
        "        return x                  # return logits (raw class scores)\n",
        "\n",
        "# Initialize the model\n",
        "model = FashionCNN().to(DEVICE)\n",
        "\n",
        "#----------------------------\n",
        "# Loss & Optimizer\n",
        "#----------------------------\n",
        "criterion = nn.CrossEntropyLoss()                 # Cross entropy for multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR) # Adam optimizer\n",
        "\n",
        "# ---------------------------\n",
        "# Train loop for one epoch\n",
        "# ---------------------------\n",
        "def train_one_epoch(epoch):\n",
        "    model.train()                            # training mode\n",
        "    running_loss, correct, total = 0.0, 0, 0 # track stats\n",
        "\n",
        "    for images, labels in train_loader:      # loop over training data\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE) # move data to device\n",
        "\n",
        "        optimizer.zero_grad()                # reset gradients\n",
        "        logits = model(images)               # forward pass\n",
        "        loss = criterion(logits, labels)     # compute loss\n",
        "        loss.backward()                      # backward pass\n",
        "        optimizer.step()                     # update weights\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)  # accumulate loss\n",
        "        preds = logits.argmax(dim=1)                  # predicted classes\n",
        "        correct += (preds == labels).sum().item()     # correct predictions\n",
        "        total += labels.size(0)                       # total samples\n",
        "\n",
        "    epoch_loss = running_loss / total                 # average loss\n",
        "    epoch_acc = correct / total                       # accuracy\n",
        "    print(f\"Epoch {epoch}: train loss={epoch_loss:.4f}, acc={epoch_acc:.4f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Evaluation function\n",
        "# ---------------------------\n",
        "@torch.no_grad()                   # no gradient tracking\n",
        "def evaluate():\n",
        "    model.eval()                   # evaluation mode\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    for images, labels in test_loader:  # loop over test data\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        logits = model(images)          # forward pass\n",
        "        preds = logits.argmax(dim=1)    # predictions\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total   += labels.size(0)\n",
        "\n",
        "    return correct / total              # return accuracy\n",
        "\n",
        "# ---------------------------\n",
        "# Run training loop\n",
        "# ---------------------------\n",
        "best_acc = 0.0                                     # best accuracy so far\n",
        "Path(\"checkpoints\").mkdir(exist_ok=True)           # make checkpoints folder\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):                 # for each epoch\n",
        "    train_one_epoch(epoch)                         # train model\n",
        "    test_acc = evaluate()                          # evaluate model\n",
        "    print(f\"Test acc after epoch {epoch}: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
        "\n",
        "    if test_acc > best_acc:                        # save if accuracy improves\n",
        "        best_acc = test_acc\n",
        "        torch.save(model.state_dict(), \"checkpoints/fashion_cnn_best.pt\")\n",
        "        print(f\"Saved new best model with acc={best_acc:.4f} ({best_acc*100:.2f}%)\")\n",
        "\n",
        "print(f\"Best test accuracy: {best_acc:.4f} ({best_acc*100:.2f}%)\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
