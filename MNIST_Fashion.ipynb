{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "                                                          #----------------------------------------\n",
        "                                                                   #Student Information#\n",
        "                                                          #----------------------------------------\n",
        "                                                           # David Engstrom - Student ID: 301537614\n",
        "                                                           # Brian Salas    - Student ID: 301789398\n",
        "\n",
        "# This dataset is for our second (student choice) neural network - using MNIST Fashion\n",
        "\n",
        "#Import Pytorch\n",
        "import torch                      # Deep learning framework\n",
        "#Import torch neural network\n",
        "import torch.nn as nn             # Neural network layers, activations, etc.\n",
        "#Import torch optimization\n",
        "import torch.optim as optim       # Optimization algorithms (Adam, SGD, etc.)\n",
        "#Get the torch DataLoader class\n",
        "from torch.utils.data import DataLoader  # For batching and shuffling data\n",
        "#Get the ready-to-use datasets and image preprocessing functions\n",
        "from torchvision import datasets, transforms # Provides datasets like FashionMNIST\n",
        "#Handles file paths cleaner and safer across OS\n",
        "from pathlib import Path\n",
        "\n",
        "#----------------------------\n",
        "# Config / Hyperparameters\n",
        "#----------------------------\n",
        "BATCH_SIZE = 128   # Number of samples per mini-batch\n",
        "EPOCHS = 5         # Number of times the dataset is processed fully\n",
        "LR = 1e-3          # Learning rate for optimizer\n",
        "SEED = 11          # Random seed for reproducibility\n",
        "DEVICE = \"cpu\"     # Run on CPU only\n",
        "\n",
        "torch.manual_seed(SEED)  # Fix randomness for reproducibility\n",
        "\n",
        "#----------------------------\n",
        "# Fashion-MNIST preprocessing\n",
        "#----------------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),               # Convert images to tensors\n",
        "    transforms.Normalize((0.5,), (0.5,)) # Normalize pixel values to mean=0.5, std=0.5\n",
        "])\n",
        "\n",
        "#Load the Fashion-MNIST training dataset (60,000 images)\n",
        "train_ds = datasets.FashionMNIST(root=\"data\", train=True, download=True, transform=transform)\n",
        "\n",
        "#Load the Fashion-MNIST test dataset (10,000 images)\n",
        "test_ds  = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=transform)\n",
        "\n",
        "#Wrap training dataset in DataLoader: batches of BATCH_SIZE, shuffled each epoch\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "#Wrap test dataset in DataLoader: batches of BATCH_SIZE, no shuffle\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
        "\n",
        "#----------------------------\n",
        "# Define a Convolutional Neural Network (CNN) for Fashion-MNIST\n",
        "#----------------------------\n",
        "class FashionCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Convolutional feature extractor\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, padding=1),   # input=1 channel (grayscale), output=32 filters\n",
        "            nn.ReLU(inplace=True),                        # activation function\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # 32 → 64 filters\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),                              # downsample: 28x28 → 14x14\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # 64 → 128 filters\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2),                              # downsample: 14x14 → 7x7\n",
        "        )\n",
        "\n",
        "        # Fully connected classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),                                 # flatten into 1D vector\n",
        "            nn.Linear(128 * 7 * 7, 256),                  # fully connected layer\n",
        "            nn.ReLU(inplace=True),                        # activation\n",
        "            nn.Dropout(0.3),                              # dropout to reduce overfitting\n",
        "            nn.Linear(256, 10)                            # output layer: 10 classes (clothing categories)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)      # apply convolution + pooling\n",
        "        x = self.classifier(x)    # apply fully connected layers\n",
        "        return x                  # return logits (raw class scores)\n",
        "\n",
        "# Initialize the model\n",
        "model = FashionCNN().to(DEVICE)\n",
        "\n",
        "#----------------------------\n",
        "# Loss & Optimizer\n",
        "#----------------------------\n",
        "criterion = nn.CrossEntropyLoss()                 # Cross entropy for multi-class classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR) # Adam optimizer\n",
        "\n",
        "# ---------------------------\n",
        "# Train loop for one epoch\n",
        "# ---------------------------\n",
        "def train_one_epoch(epoch):\n",
        "    model.train()                            # training mode\n",
        "    running_loss, correct, total = 0.0, 0, 0 # track stats\n",
        "\n",
        "    for images, labels in train_loader:      # loop over training data\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE) # move data to device\n",
        "\n",
        "        optimizer.zero_grad()                # reset gradients\n",
        "        logits = model(images)               # forward pass\n",
        "        loss = criterion(logits, labels)     # compute loss\n",
        "        loss.backward()                      # backward pass\n",
        "        optimizer.step()                     # update weights\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)  # accumulate loss\n",
        "        preds = logits.argmax(dim=1)                  # predicted classes\n",
        "        correct += (preds == labels).sum().item()     # correct predictions\n",
        "        total += labels.size(0)                       # total samples\n",
        "\n",
        "    epoch_loss = running_loss / total                 # average loss\n",
        "    epoch_acc = correct / total                       # accuracy\n",
        "    print(f\"Epoch {epoch}: train loss={epoch_loss:.4f}, acc={epoch_acc:.4f}\")\n",
        "\n",
        "# ---------------------------\n",
        "# Evaluation function\n",
        "# ---------------------------\n",
        "@torch.no_grad()                   # no gradient tracking\n",
        "def evaluate():\n",
        "    model.eval()                   # evaluation mode\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    for images, labels in test_loader:  # loop over test data\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        logits = model(images)          # forward pass\n",
        "        preds = logits.argmax(dim=1)    # predictions\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total   += labels.size(0)\n",
        "\n",
        "    return correct / total              # return accuracy\n",
        "\n",
        "# ---------------------------\n",
        "# Run training loop\n",
        "# ---------------------------\n",
        "best_acc = 0.0                                     # best accuracy so far\n",
        "Path(\"checkpoints\").mkdir(exist_ok=True)           # make checkpoints folder\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):                 # for each epoch\n",
        "    train_one_epoch(epoch)                         # train model\n",
        "    test_acc = evaluate()                          # evaluate model\n",
        "    print(f\"Test acc after epoch {epoch}: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
        "\n",
        "    if test_acc > best_acc:                        # save if accuracy improves\n",
        "        best_acc = test_acc\n",
        "        torch.save(model.state_dict(), \"checkpoints/fashion_cnn_best.pt\")\n",
        "        print(f\"Saved new best model with acc={best_acc:.4f} ({best_acc*100:.2f}%)\")\n",
        "\n",
        "print(f\"Best test accuracy: {best_acc:.4f} ({best_acc*100:.2f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUyZdPp_B5IF",
        "outputId": "1ece5b91-8569-4a03-f2e1-8d731b45d9ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train loss=0.4502, acc=0.8360\n",
            "Test acc after epoch 1: 0.8799 (87.99%)\n",
            "Saved new best model with acc=0.8799 (87.99%)\n",
            "Epoch 2: train loss=0.2632, acc=0.9055\n",
            "Test acc after epoch 2: 0.9082 (90.82%)\n",
            "Saved new best model with acc=0.9082 (90.82%)\n",
            "Epoch 3: train loss=0.2152, acc=0.9224\n",
            "Test acc after epoch 3: 0.9190 (91.90%)\n",
            "Saved new best model with acc=0.9190 (91.90%)\n",
            "Epoch 4: train loss=0.1811, acc=0.9338\n",
            "Test acc after epoch 4: 0.9238 (92.38%)\n",
            "Saved new best model with acc=0.9238 (92.38%)\n",
            "Epoch 5: train loss=0.1551, acc=0.9433\n",
            "Test acc after epoch 5: 0.9220 (92.20%)\n",
            "Best test accuracy: 0.9238 (92.38%)\n"
          ]
        }
      ]
    }
  ]
}