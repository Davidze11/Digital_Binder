{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEnhi_4oIkKs",
        "outputId": "e2767e37-7a67-454a-b233-ad40b63db2c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 and loss: 1.1886601448059082\n",
            "Epoch: 10 and loss: 0.9812762141227722\n",
            "Epoch: 20 and loss: 0.7062868475914001\n",
            "Epoch: 30 and loss: 0.43727999925613403\n",
            "Epoch: 40 and loss: 0.2936667799949646\n",
            "Epoch: 50 and loss: 0.18380619585514069\n",
            "Epoch: 60 and loss: 0.11441708356142044\n",
            "Epoch: 70 and loss: 0.08289751410484314\n",
            "Epoch: 80 and loss: 0.06866930425167084\n",
            "Epoch: 90 and loss: 0.06146979704499245\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3987243608.py:54: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  my_df['species'] = my_df['species'].replace('virginica', 2.0)\n"
          ]
        }
      ],
      "source": [
        "  #*STUDENT INFORMATION*#\n",
        "  # DAVID ENGSTROM\n",
        "  # STUDENT ID: 301537614\n",
        "\n",
        "                              # ASSIGNMENT: LAB 1 - FEATURE ENGINEERING #\n",
        "                                         ## NN INFORMATION ##\n",
        "# ----------------------------------------------------------------------------------------------------*\n",
        "# The dataset is from GitHub and contains 150 samples of Iris Flowers.\n",
        "# It's training a neural network classifier to predict whether a flower is Setosa, Versicolor, or Virginica based on petal and sepal measurements.\n",
        "# The model predicts flower species for each training example, loss values, & updates network weights every epoch, so the model learns the classification task.\n",
        "# ----------------------------------------------------------------------------------------------------*\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Create a Model Class that inherits nn.Module\n",
        "class Model(nn.Module):\n",
        "\n",
        "    # Input layer (4 features of the flower)\n",
        "    # Hidden Layer1 (number of neurons)\n",
        "    # H(n)\n",
        "    # Output (3 classes of iris flower)\n",
        "    def __init__(self, in_features=4, h1=8, h2=9, out_features=3):\n",
        "        super().__init__() # instantiate our nn.Module\n",
        "        self.fc1 = nn.Linear(in_features, h1)\n",
        "        self.fc2 = nn.Linear(h1, h2)\n",
        "        self.out = nn.Linear(h2, out_features)\n",
        "\n",
        "    def forward(self, x):       # Forward Pass\n",
        "        x = F.relu(self.fc1(x)) # First layer + ReLU\n",
        "        x = F.relu(self.fc2(x)) # Second layer + ReLU\n",
        "        x = self.out(x)         # Output layer (logits)\n",
        "        return x                # Return predictions\n",
        "\n",
        "# manual seed for randomization\n",
        "torch.manual_seed(11)\n",
        "\n",
        "# Create an instance of model\n",
        "model = Model()\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt # Import plotting library (added this to visual data)\n",
        "%matplotlib inline\n",
        "\n",
        "# Gathering my dataset and adding it as a url\n",
        "url = 'https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv'\n",
        "my_df = pd.read_csv(url)\n",
        "\n",
        "#Change last column from strings to num\n",
        "my_df['species'] = my_df['species'].replace('setosa', 0.0)\n",
        "my_df['species'] = my_df['species'].replace('versicolor', 1.0)\n",
        "my_df['species'] = my_df['species'].replace('virginica', 2.0)\n",
        "\n",
        "#Train, test & split Set X, y\n",
        "X = my_df.drop('species', axis=1)\n",
        "y = my_df['species']\n",
        "\n",
        "# Convert X, y to numpy arrays\n",
        "X = X.values\n",
        "y = y.values\n",
        "\n",
        "# Split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11) #setting test size to 20% and keeping random state to seed 11\n",
        "\n",
        "# Convert X features to float tensors\n",
        "X_train = torch.FloatTensor(X_train)\n",
        "X_test = torch.FloatTensor(X_test)\n",
        "\n",
        "# Convert y labels to tensors long\n",
        "y_train = torch.LongTensor(y_train)\n",
        "y_test = torch.LongTensor(y_test)\n",
        "\n",
        "# Set the criterion of model to measure the error, how far off the predictions are from the data\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Choose an Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01) # Using Adam Optimizer, lr = learning rate (if error doesn't go down after a bunch of iterations (epochs))\n",
        "\n",
        "# Train model\n",
        "# Set epoch\n",
        "epochs = 100\n",
        "losses = []\n",
        "for i in range(epochs):\n",
        "  # Go forward and get a prediction\n",
        "    y_pred = model.forward(X_train) # Get predicted results\n",
        "    loss = criterion(y_pred, y_train) # Measure the loss/error (predicted values vs the y_train)\n",
        "    losses.append(loss.detach().numpy()) # Keep track of losses\n",
        "  # Print every 10 epochs\n",
        "    if i % 10 == 0:\n",
        "        print(f'Epoch: {i} and loss: {loss}')\n",
        "\n",
        "  # Back propagation: take error rate of forw. prop. and feed it back into network to fine tune weights\n",
        "    optimizer.zero_grad() # Zero the gradients\n",
        "    loss.backward() # Back propagate\n",
        "    optimizer.step() # Update the weights"
      ]
    }
  ]
}